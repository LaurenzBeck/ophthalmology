
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="../../../../docs/images/retina.jpg">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.3.0">
    
    
      
        <title>Modules - ophthalmology</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.8b42a75e.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.3f5d1f46.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    <script>function __prefix(e){return new URL("../../../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-ophthalmologydatamodules" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="ophthalmology" class="md-header__button md-logo" aria-label="ophthalmology" data-md-component="logo">
      
  <img src="../../../../docs/images/retina.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ophthalmology
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Modules
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/LaurenzBeck/ophthalmology/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ophthalmology
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="ophthalmology" class="md-nav__button md-logo" aria-label="ophthalmology" data-md-component="logo">
      
  <img src="../../../../docs/images/retina.jpg" alt="logo">

    </a>
    ophthalmology
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/LaurenzBeck/ophthalmology/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ophthalmology
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/datasets/" class="md-nav__link">
        Datasets
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../docs/experiments/" class="md-nav__link">
        Experiments
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1" type="checkbox" id="__nav_4_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1">
          Ophthalmology
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Ophthalmology" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          Ophthalmology
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../callbacks/" class="md-nav__link">
        Callbacks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../samplers/" class="md-nav__link">
        Samplers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../utils/" class="md-nav__link">
        Utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../visualization/" class="md-nav__link">
        Visualization
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_6" type="checkbox" id="__nav_4_1_6" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_6">
          Data
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Data" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_6">
          <span class="md-nav__icon md-icon"></span>
          Data
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Modules
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Modules
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#datamodules" class="md-nav__link">
    datamodules
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diabeticretinopythydetection" class="md-nav__link">
    DiabeticRetinopythyDetection
  </a>
  
    <nav class="md-nav" aria-label="DiabeticRetinopythyDetection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indiandiabeticretinopythydetection" class="md-nav__link">
    IndianDiabeticRetinopythyDetection
  </a>
  
    <nav class="md-nav" aria-label="IndianDiabeticRetinopythyDetection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_1" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_1" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args_1" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args_1" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets_1" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types_1" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer_1" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer_1" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint_1" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader_1" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint_1" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader_1" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader_1" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader_1" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader_1" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data_1" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters_1" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup_1" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size_1" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown_1" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader_1" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader_1" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device_1" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader_1" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indiandiabeticretinopythydetectionlocalization" class="md-nav__link">
    IndianDiabeticRetinopythyDetectionLocalization
  </a>
  
    <nav class="md-nav" aria-label="IndianDiabeticRetinopythyDetectionLocalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_2" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_2" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args_2" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args_2" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets_2" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types_2" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_2" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer_2" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer_2" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint_2" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader_2" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint_2" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader_2" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader_2" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader_2" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader_2" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data_2" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters_2" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup_2" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size_2" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown_2" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader_2" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader_2" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device_2" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader_2" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retinamnist" class="md-nav__link">
    RetinaMNIST
  </a>
  
    <nav class="md-nav" aria-label="RetinaMNIST">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_3" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_3" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_3" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args_3" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args_3" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets_3" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types_3" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_3" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_3" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer_3" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer_3" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint_3" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader_3" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint_3" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader_3" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader_3" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader_3" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader_3" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data_3" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters_3" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup_3" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size_3" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown_3" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader_3" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader_3" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device_3" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader_3" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ssldiabeticretinopythydetection" class="md-nav__link">
    SSLDiabeticRetinopythyDetection
  </a>
  
    <nav class="md-nav" aria-label="SSLDiabeticRetinopythyDetection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_4" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_4" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_4" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args_4" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args_4" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets_4" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types_4" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_4" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_4" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer_4" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer_4" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint_4" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader_4" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint_4" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader_4" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader_4" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader_4" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader_4" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data_4" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters_4" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup_4" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size_4" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown_4" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader_4" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader_4" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device_4" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader_4" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../sets/" class="md-nav__link">
        Sets
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_7" type="checkbox" id="__nav_4_1_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_7">
          Layers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Layers" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_7">
          <span class="md-nav__icon md-icon"></span>
          Layers
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/activations/" class="md-nav__link">
        Activations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/assp/" class="md-nav__link">
        Assp
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/convolutional_stems/" class="md-nav__link">
        Convolutional Stems
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/involution/" class="md-nav__link">
        Involution
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/losses/" class="md-nav__link">
        Losses
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/noise/" class="md-nav__link">
        Noise
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/residual_blocks/" class="md-nav__link">
        Residual Blocks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/squeeze_and_excitation/" class="md-nav__link">
        Squeeze And Excitation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../layers/transforms/" class="md-nav__link">
        Transforms
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_8" type="checkbox" id="__nav_4_1_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_8">
          Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Models" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_8">
          <span class="md-nav__icon md-icon"></span>
          Models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../models/attentive_nf_resnet/" class="md-nav__link">
        Attentive Nf Resnet
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../models/heads/" class="md-nav__link">
        Heads
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../models/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../models/resnet/" class="md-nav__link">
        Resnet
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_1_9" type="checkbox" id="__nav_4_1_9" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_1_9">
          Modules
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Modules" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_1_9">
          <span class="md-nav__icon md-icon"></span>
          Modules
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/disease_grading/" class="md-nav__link">
        Disease Grading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/" class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/localization/" class="md-nav__link">
        Localization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../modules/simclr/" class="md-nav__link">
        Simclr
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#datamodules" class="md-nav__link">
    datamodules
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#diabeticretinopythydetection" class="md-nav__link">
    DiabeticRetinopythyDetection
  </a>
  
    <nav class="md-nav" aria-label="DiabeticRetinopythyDetection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indiandiabeticretinopythydetection" class="md-nav__link">
    IndianDiabeticRetinopythyDetection
  </a>
  
    <nav class="md-nav" aria-label="IndianDiabeticRetinopythyDetection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_1" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_1" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_1" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args_1" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args_1" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets_1" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types_1" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_1" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_1" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer_1" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer_1" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint_1" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader_1" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint_1" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader_1" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader_1" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader_1" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader_1" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data_1" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters_1" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup_1" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size_1" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown_1" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader_1" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader_1" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device_1" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader_1" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#indiandiabeticretinopythydetectionlocalization" class="md-nav__link">
    IndianDiabeticRetinopythyDetectionLocalization
  </a>
  
    <nav class="md-nav" aria-label="IndianDiabeticRetinopythyDetectionLocalization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_2" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_2" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_2" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args_2" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args_2" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets_2" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types_2" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_2" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_2" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer_2" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer_2" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint_2" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader_2" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint_2" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader_2" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader_2" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader_2" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader_2" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data_2" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters_2" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup_2" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size_2" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown_2" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader_2" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader_2" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device_2" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader_2" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#retinamnist" class="md-nav__link">
    RetinaMNIST
  </a>
  
    <nav class="md-nav" aria-label="RetinaMNIST">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_3" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_3" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_3" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args_3" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args_3" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets_3" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types_3" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_3" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_3" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer_3" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer_3" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint_3" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader_3" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint_3" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader_3" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader_3" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader_3" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader_3" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data_3" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters_3" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup_3" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size_3" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown_3" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader_3" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader_3" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device_3" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader_3" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ssldiabeticretinopythydetection" class="md-nav__link">
    SSLDiabeticRetinopythyDetection
  </a>
  
    <nav class="md-nav" aria-label="SSLDiabeticRetinopythyDetection">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro_4" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#class-variables_4" class="md-nav__link">
    Class variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods_4" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add_argparse_args_4" class="md-nav__link">
    add_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_argparse_args_4" class="md-nav__link">
    from_argparse_args
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_datasets_4" class="md-nav__link">
    from_datasets
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#get_init_arguments_and_types_4" class="md-nav__link">
    get_init_arguments_and_types
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables_4" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods_4" class="md-nav__link">
    Methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_after_batch_transfer_4" class="md-nav__link">
    on_after_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_before_batch_transfer_4" class="md-nav__link">
    on_before_batch_transfer
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_load_checkpoint_4" class="md-nav__link">
    on_load_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_predict_dataloader_4" class="md-nav__link">
    on_predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_save_checkpoint_4" class="md-nav__link">
    on_save_checkpoint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_test_dataloader_4" class="md-nav__link">
    on_test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_train_dataloader_4" class="md-nav__link">
    on_train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on_val_dataloader_4" class="md-nav__link">
    on_val_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#predict_dataloader_4" class="md-nav__link">
    predict_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prepare_data_4" class="md-nav__link">
    prepare_data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#save_hyperparameters_4" class="md-nav__link">
    save_hyperparameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setup_4" class="md-nav__link">
    setup
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size_4" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#teardown_4" class="md-nav__link">
    teardown
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test_dataloader_4" class="md-nav__link">
    test_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train_dataloader_4" class="md-nav__link">
    train_dataloader
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transfer_batch_to_device_4" class="md-nav__link">
    transfer_batch_to_device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#val_dataloader_4" class="md-nav__link">
    val_dataloader
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/LaurenzBeck/ophthalmology/edit/main/reference/ophthalmology/data/modules.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="module-ophthalmologydatamodules">Module ophthalmology.data.modules</h1>
<h2 id="datamodules">datamodules</h2>
<p>This module contains the pytorch_lightning datamodules for the different tasks and datasets</p>
<h2 id="classes">Classes</h2>
<h3 id="diabeticretinopythydetection">DiabeticRetinopythyDetection</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">DiabeticRetinopythyDetection</span><span class="p">(</span>
    <span class="n">train_transform</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">image_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file_train</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file_test</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">test_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_test_split</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="n">balanced_sampling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>pytorch_lightning.core.datamodule.LightningDataModule</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
</ul>
<h4 id="class-variables">Class variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">name</span>
</code></pre></div>
<h4 id="static-methods">Static methods</h4>
<h4 id="add_argparse_args">add_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">add_argparse_args</span><span class="p">(</span>
    <span class="n">parent_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span>
</code></pre></div>
<p>Extends existing argparse by default <code>LightningDataModule</code> attributes.</p>
<h4 id="from_argparse_args">from_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_argparse_args</span><span class="p">(</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from CLI arguments.</p>
<p>Args:
    args: The parser or namespace to take arguments from. Only known arguments will be
        parsed and passed to the :class:<code>~pytorch_lightning.core.datamodule.LightningDataModule</code>.
    **kwargs: Additional keyword arguments that may override ones in the parser or namespace.
        These must be valid DataModule arguments.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>parser = ArgumentParser(add_help=False)
parser = LightningDataModule.add_argparse_args(parser)
module = LightningDataModule.from_argparse_args(args)
</code></pre></div>
<h4 id="from_datasets">from_datasets</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_datasets</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from torch.utils.data.Dataset.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>train_dataset</td>
<td>None</td>
<td>(optional) Dataset to be used for train_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>val_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for val_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>test_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for test_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Batch size to use for each dataloader. Default is 1.</td>
<td>None</td>
</tr>
<tr>
<td>num_workers</td>
<td>None</td>
<td>Number of subprocesses to use for data loading. 0 means that the</td>
<td></td>
</tr>
<tr>
<td>data will be loaded in the main process. Number of CPUs available.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="get_init_arguments_and_types">get_init_arguments_and_types</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_init_arguments_and_types</span><span class="p">(</span>

<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</code></pre></div>
<p>Scans the DataModule signature and returns argument names, types and default values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List with tuples of 3 values:</td>
</tr>
<tr>
<td>(argument name, set with argument types, argument default value).</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="instance-variables">Instance variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">dims</span>
</code></pre></div>
<p>A tuple describing the shape of your data. Extra functionality exposed in <code>size</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_prepared_data</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.prepare_data()</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. It is mutable by the user.</p>
<p>For the frozen set of initial hyperparameters, use :attr:<code>hparams_initial</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams_initial</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. These contents are read-only.</p>
<p>Manual updates to the saved hyperparameters can instead be performed through :attr:<code>hparams</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">test_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to test dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">train_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to train dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">val_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to validation dataset.</p>
<h4 id="methods">Methods</h4>
<h4 id="on_after_batch_transfer">on_after_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_after_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = gpu_transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_before_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_before_batch_transfer">on_before_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_before_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_after_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_load_checkpoint">on_load_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning to restore your model.
If you saved something with :meth:<code>on_save_checkpoint</code> this is your chance to restore this.</p>
<p>Args:
    checkpoint: Loaded checkpoint</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_load_checkpoint(self, checkpoint):
    # 99% of the time you don&#39;t need to implement this method
    self.something_cool_i_want_to_save = checkpoint[&#39;something_cool_i_want_to_save&#39;]
</code></pre></div>
<p>Note:
    Lightning auto-restores global step, epoch, and train state including amp scaling.
    There is no need for you to restore anything regarding training.</p>
<h4 id="on_predict_dataloader">on_predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the predict dataloader.</p>
<h4 id="on_save_checkpoint">on_save_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning when saving a checkpoint to give you a chance to store anything
else you might want to save.</p>
<p>Args:
    checkpoint: The full checkpoint dictionary before it gets dumped to a file.
        Implementations of this hook can insert additional data into this dictionary.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_save_checkpoint(self, checkpoint):
    # 99% of use cases you don&#39;t need to implement this method
    checkpoint[&#39;something_cool_i_want_to_save&#39;] = my_cool_pickable_object
</code></pre></div>
<p>Note:
    Lightning saves all aspects of training (epoch, global step, etc...)
    including amp scaling.
    There is no need for you to store anything about training.</p>
<h4 id="on_test_dataloader">on_test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the test dataloader.</p>
<h4 id="on_train_dataloader">on_train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the train dataloader.</p>
<h4 id="on_val_dataloader">on_val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the val dataloader.</p>
<h4 id="predict_dataloader">predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]]</span>
</code></pre></div>
<p>Implement one or multiple PyTorch DataLoaders for prediction.</p>
<p>It's recommended that all data downloads and preparation happen in :meth:<code>prepare_data</code>.</p>
<ul>
<li>:meth:<code>~pytorch_lightning.trainer.Trainer.fit</code></li>
<li>...</li>
<li>:meth:<code>prepare_data</code></li>
<li>:meth:<code>train_dataloader</code></li>
<li>:meth:<code>val_dataloader</code></li>
<li>:meth:<code>test_dataloader</code></li>
</ul>
<p>Note:
    Lightning adds the correct sampler for distributed and arbitrary hardware
    There is no need to set it yourself.</p>
<p>Return:
    A :class:<code>torch.utils.data.DataLoader</code> or a sequence of them specifying prediction samples.</p>
<p>Note:
    In the case where you return multiple prediction dataloaders, the :meth:<code>predict</code>
    will have an argument <code>dataloader_idx</code> which matches the order here.</p>
<h4 id="prepare_data">prepare_data</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Use this to download and prepare data.</p>
<p>.. warning:: DO NOT set state to the model (use <code>setup</code> instead)
    since this is NOT called on every GPU in DDP/TPU</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def prepare_data(self):
    # good
    download_data()
    tokenize()
    etc()

    # bad
    self.split = data_split
    self.some_state = some_other_state()
</code></pre></div>
<p>In DDP prepare_data can be called in two ways (using Trainer(prepare_data_per_node)):</p>
<ol>
<li>Once per node. This is the default and is only called on LOCAL_RANK=0.</li>
<li>Once in total. Only called on GLOBAL_RANK=0.</li>
</ol>
<p>Example::</p>
<div class="highlight"><pre><span></span><code># DEFAULT
# called once per node on LOCAL_RANK=0 of that node
Trainer(prepare_data_per_node=True)

# call on GLOBAL_RANK=0 (great for shared file systems)
Trainer(prepare_data_per_node=False)
</code></pre></div>
<p>Note:
    Setting <code>prepare_data_per_node</code> with the trainer flag is deprecated and will be removed in v1.7.0.
    Please set <code>prepare_data_per_node</code> in LightningDataModule or LightningModule directly instead.</p>
<p>This is called before requesting the dataloaders:</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code>model.prepare_data()
initialize_distributed()
model.setup(stage)
model.train_dataloader()
model.val_dataloader()
model.test_dataloader()
</code></pre></div>
<h4 id="save_hyperparameters">save_hyperparameters</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">save_hyperparameters</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="n">ignore</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">frame</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">frame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logger</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Save arguments to <code>hparams</code> attribute.</p>
<p>Args:
    args: single object of <code>dict</code>, <code>NameSpace</code> or <code>OmegaConf</code>
        or string names or arguments from class <code>__init__</code>
    ignore: an argument name or a list of argument names from
        class <code>__init__</code> to be ignored
    frame: a frame object. Default is None
    logger: Whether to send the hyperparameters to the logger. Default: True</p>
<p>Example::
    &gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
    ...     def <strong>init</strong>(self, arg1, arg2, arg3):
    ...         super().<strong>init</strong>()
    ...         # manually assign arguments
    ...         self.save_hyperparameters('arg1', 'arg3')
    ...     def forward(self, <em>args, </em>*kwargs):
    ...         ...
    &gt;&gt;&gt; model = ManuallyArgsModel(1, 'abc', 3.14)
    &gt;&gt;&gt; model.hparams
    "arg1": 1
    "arg3": 3.14</p>
<div class="highlight"><pre><span></span><code>&gt;&gt;&gt; class AutomaticArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # equivalent automatic
...         self.save_hyperparameters()
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = AutomaticArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg2&quot;: abc
&quot;arg3&quot;: 3.14

&gt;&gt;&gt; class SingleArgModel(HyperparametersMixin):
...     def __init__(self, params):
...         super().__init__()
...         # manually assign single argument
...         self.save_hyperparameters(params)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = SingleArgModel(Namespace(p1=1, p2=&#39;abc&#39;, p3=3.14))
&gt;&gt;&gt; model.hparams
&quot;p1&quot;: 1
&quot;p2&quot;: abc
&quot;p3&quot;: 3.14

&gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # pass argument(s) to ignore as a string or in a list
...         self.save_hyperparameters(ignore=&#39;arg2&#39;)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = ManuallyArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg3&quot;: 3.14
</code></pre></div>
<h4 id="setup">setup</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">setup</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the beginning of fit (train + validate), validate, test, and predict. This is a good hook when</p>
<p>you need to build models dynamically or adjust something about them. This hook is called on every process
when using DDP.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td></td>
</tr>
<tr>
<td>Example::</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>class LitModel</td>
<td>...</td>
<td>def <strong>init</strong>(self):</td>
<td></td>
</tr>
<tr>
<td>self.l1 = None</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>def prepare_data(self):
    download_data()
    tokenize()</p>
<div class="highlight"><pre><span></span><code># don&#39;t do this
self.something = else
</code></pre></div>
<p>def setup(stage):
    data = Load_data(...)
    self.l1 = nn.Linear(28, data.num_classes) | None |</p>
<h4 id="size">size</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">size</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]]</span>
</code></pre></div>
<p>Return the dimension of each input either as a tuple or list of tuples. You can index this just as you</p>
<p>would with a torch tensor.</p>
<h4 id="teardown">teardown</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the end of fit (train + validate), validate, test, predict, or tune.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td>None</td>
</tr>
</tbody>
</table>
<h4 id="test_dataloader">test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Testing data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="train_dataloader">train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Train data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="transfer_batch_to_device">transfer_batch_to_device</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override this hook if your :class:<code>~torch.utils.data.DataLoader</code> returns tensors wrapped in a custom</p>
<p>data structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul>
<li>:class:<code>torch.Tensor</code> or anything that implements <code>.to(...)</code></li>
<li>:class:<code>list</code></li>
<li>:class:<code>dict</code></li>
<li>:class:<code>tuple</code></li>
<li>:class:<code>torchtext.data.batch.Batch</code></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, ...).</p>
<p>Note:
    This hook should only transfer the data and not modify it, nor should it move the data to
    any other device than the one passed in as argument (unless you know what you are doing).
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be transferred to a new device.</td>
<td>None</td>
</tr>
<tr>
<td>device</td>
<td>None</td>
<td>The target device as defined in PyTorch.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A reference to the data on the new device.</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def transfer_batch_to_device(self, batch, device, dataloader_idx):
    if isinstance(batch, CustomBatch):
        # move all tensors in your custom data structure to the device
        batch.samples = batch.samples.to(device)
        batch.targets = batch.targets.to(device)
    elif dataloader_idx == 0:
        # skip device transfer for the first dataloader or anything you wish
        pass
    else:
        batch = super().transfer_batch_to_device(data, device)
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>move_data_to_device</code> |
| -  | meth:<code>apply_to_collection</code> |</p>
<h4 id="val_dataloader">val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Validation data loader for the given input</td>
</tr>
</tbody>
</table>
<h3 id="indiandiabeticretinopythydetection">IndianDiabeticRetinopythyDetection</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">IndianDiabeticRetinopythyDetection</span><span class="p">(</span>
    <span class="n">train_transform</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">image_dir_train</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">image_dir_test</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file_train</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file_test</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">test_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_test_split</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="n">balanced_sampling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>pytorch_lightning.core.datamodule.LightningDataModule</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
</ul>
<h4 id="class-variables_1">Class variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">name</span>
</code></pre></div>
<h4 id="static-methods_1">Static methods</h4>
<h4 id="add_argparse_args_1">add_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">add_argparse_args</span><span class="p">(</span>
    <span class="n">parent_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span>
</code></pre></div>
<p>Extends existing argparse by default <code>LightningDataModule</code> attributes.</p>
<h4 id="from_argparse_args_1">from_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_argparse_args</span><span class="p">(</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from CLI arguments.</p>
<p>Args:
    args: The parser or namespace to take arguments from. Only known arguments will be
        parsed and passed to the :class:<code>~pytorch_lightning.core.datamodule.LightningDataModule</code>.
    **kwargs: Additional keyword arguments that may override ones in the parser or namespace.
        These must be valid DataModule arguments.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>parser = ArgumentParser(add_help=False)
parser = LightningDataModule.add_argparse_args(parser)
module = LightningDataModule.from_argparse_args(args)
</code></pre></div>
<h4 id="from_datasets_1">from_datasets</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_datasets</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from torch.utils.data.Dataset.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>train_dataset</td>
<td>None</td>
<td>(optional) Dataset to be used for train_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>val_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for val_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>test_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for test_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Batch size to use for each dataloader. Default is 1.</td>
<td>None</td>
</tr>
<tr>
<td>num_workers</td>
<td>None</td>
<td>Number of subprocesses to use for data loading. 0 means that the</td>
<td></td>
</tr>
<tr>
<td>data will be loaded in the main process. Number of CPUs available.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="get_init_arguments_and_types_1">get_init_arguments_and_types</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_init_arguments_and_types</span><span class="p">(</span>

<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</code></pre></div>
<p>Scans the DataModule signature and returns argument names, types and default values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List with tuples of 3 values:</td>
</tr>
<tr>
<td>(argument name, set with argument types, argument default value).</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="instance-variables_1">Instance variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">dims</span>
</code></pre></div>
<p>A tuple describing the shape of your data. Extra functionality exposed in <code>size</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_prepared_data</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.prepare_data()</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. It is mutable by the user.</p>
<p>For the frozen set of initial hyperparameters, use :attr:<code>hparams_initial</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams_initial</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. These contents are read-only.</p>
<p>Manual updates to the saved hyperparameters can instead be performed through :attr:<code>hparams</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">test_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to test dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">train_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to train dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">val_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to validation dataset.</p>
<h4 id="methods_1">Methods</h4>
<h4 id="on_after_batch_transfer_1">on_after_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_after_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = gpu_transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_before_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_before_batch_transfer_1">on_before_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_before_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_after_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_load_checkpoint_1">on_load_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning to restore your model.
If you saved something with :meth:<code>on_save_checkpoint</code> this is your chance to restore this.</p>
<p>Args:
    checkpoint: Loaded checkpoint</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_load_checkpoint(self, checkpoint):
    # 99% of the time you don&#39;t need to implement this method
    self.something_cool_i_want_to_save = checkpoint[&#39;something_cool_i_want_to_save&#39;]
</code></pre></div>
<p>Note:
    Lightning auto-restores global step, epoch, and train state including amp scaling.
    There is no need for you to restore anything regarding training.</p>
<h4 id="on_predict_dataloader_1">on_predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the predict dataloader.</p>
<h4 id="on_save_checkpoint_1">on_save_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning when saving a checkpoint to give you a chance to store anything
else you might want to save.</p>
<p>Args:
    checkpoint: The full checkpoint dictionary before it gets dumped to a file.
        Implementations of this hook can insert additional data into this dictionary.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_save_checkpoint(self, checkpoint):
    # 99% of use cases you don&#39;t need to implement this method
    checkpoint[&#39;something_cool_i_want_to_save&#39;] = my_cool_pickable_object
</code></pre></div>
<p>Note:
    Lightning saves all aspects of training (epoch, global step, etc...)
    including amp scaling.
    There is no need for you to store anything about training.</p>
<h4 id="on_test_dataloader_1">on_test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the test dataloader.</p>
<h4 id="on_train_dataloader_1">on_train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the train dataloader.</p>
<h4 id="on_val_dataloader_1">on_val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the val dataloader.</p>
<h4 id="predict_dataloader_1">predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]]</span>
</code></pre></div>
<p>Implement one or multiple PyTorch DataLoaders for prediction.</p>
<p>It's recommended that all data downloads and preparation happen in :meth:<code>prepare_data</code>.</p>
<ul>
<li>:meth:<code>~pytorch_lightning.trainer.Trainer.fit</code></li>
<li>...</li>
<li>:meth:<code>prepare_data</code></li>
<li>:meth:<code>train_dataloader</code></li>
<li>:meth:<code>val_dataloader</code></li>
<li>:meth:<code>test_dataloader</code></li>
</ul>
<p>Note:
    Lightning adds the correct sampler for distributed and arbitrary hardware
    There is no need to set it yourself.</p>
<p>Return:
    A :class:<code>torch.utils.data.DataLoader</code> or a sequence of them specifying prediction samples.</p>
<p>Note:
    In the case where you return multiple prediction dataloaders, the :meth:<code>predict</code>
    will have an argument <code>dataloader_idx</code> which matches the order here.</p>
<h4 id="prepare_data_1">prepare_data</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Use this to download and prepare data.</p>
<p>.. warning:: DO NOT set state to the model (use <code>setup</code> instead)
    since this is NOT called on every GPU in DDP/TPU</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def prepare_data(self):
    # good
    download_data()
    tokenize()
    etc()

    # bad
    self.split = data_split
    self.some_state = some_other_state()
</code></pre></div>
<p>In DDP prepare_data can be called in two ways (using Trainer(prepare_data_per_node)):</p>
<ol>
<li>Once per node. This is the default and is only called on LOCAL_RANK=0.</li>
<li>Once in total. Only called on GLOBAL_RANK=0.</li>
</ol>
<p>Example::</p>
<div class="highlight"><pre><span></span><code># DEFAULT
# called once per node on LOCAL_RANK=0 of that node
Trainer(prepare_data_per_node=True)

# call on GLOBAL_RANK=0 (great for shared file systems)
Trainer(prepare_data_per_node=False)
</code></pre></div>
<p>Note:
    Setting <code>prepare_data_per_node</code> with the trainer flag is deprecated and will be removed in v1.7.0.
    Please set <code>prepare_data_per_node</code> in LightningDataModule or LightningModule directly instead.</p>
<p>This is called before requesting the dataloaders:</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code>model.prepare_data()
initialize_distributed()
model.setup(stage)
model.train_dataloader()
model.val_dataloader()
model.test_dataloader()
</code></pre></div>
<h4 id="save_hyperparameters_1">save_hyperparameters</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">save_hyperparameters</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="n">ignore</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">frame</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">frame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logger</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Save arguments to <code>hparams</code> attribute.</p>
<p>Args:
    args: single object of <code>dict</code>, <code>NameSpace</code> or <code>OmegaConf</code>
        or string names or arguments from class <code>__init__</code>
    ignore: an argument name or a list of argument names from
        class <code>__init__</code> to be ignored
    frame: a frame object. Default is None
    logger: Whether to send the hyperparameters to the logger. Default: True</p>
<p>Example::
    &gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
    ...     def <strong>init</strong>(self, arg1, arg2, arg3):
    ...         super().<strong>init</strong>()
    ...         # manually assign arguments
    ...         self.save_hyperparameters('arg1', 'arg3')
    ...     def forward(self, <em>args, </em>*kwargs):
    ...         ...
    &gt;&gt;&gt; model = ManuallyArgsModel(1, 'abc', 3.14)
    &gt;&gt;&gt; model.hparams
    "arg1": 1
    "arg3": 3.14</p>
<div class="highlight"><pre><span></span><code>&gt;&gt;&gt; class AutomaticArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # equivalent automatic
...         self.save_hyperparameters()
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = AutomaticArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg2&quot;: abc
&quot;arg3&quot;: 3.14

&gt;&gt;&gt; class SingleArgModel(HyperparametersMixin):
...     def __init__(self, params):
...         super().__init__()
...         # manually assign single argument
...         self.save_hyperparameters(params)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = SingleArgModel(Namespace(p1=1, p2=&#39;abc&#39;, p3=3.14))
&gt;&gt;&gt; model.hparams
&quot;p1&quot;: 1
&quot;p2&quot;: abc
&quot;p3&quot;: 3.14

&gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # pass argument(s) to ignore as a string or in a list
...         self.save_hyperparameters(ignore=&#39;arg2&#39;)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = ManuallyArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg3&quot;: 3.14
</code></pre></div>
<h4 id="setup_1">setup</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">setup</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the beginning of fit (train + validate), validate, test, and predict. This is a good hook when</p>
<p>you need to build models dynamically or adjust something about them. This hook is called on every process
when using DDP.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td></td>
</tr>
<tr>
<td>Example::</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>class LitModel</td>
<td>...</td>
<td>def <strong>init</strong>(self):</td>
<td></td>
</tr>
<tr>
<td>self.l1 = None</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>def prepare_data(self):
    download_data()
    tokenize()</p>
<div class="highlight"><pre><span></span><code># don&#39;t do this
self.something = else
</code></pre></div>
<p>def setup(stage):
    data = Load_data(...)
    self.l1 = nn.Linear(28, data.num_classes) | None |</p>
<h4 id="size_1">size</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">size</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]]</span>
</code></pre></div>
<p>Return the dimension of each input either as a tuple or list of tuples. You can index this just as you</p>
<p>would with a torch tensor.</p>
<h4 id="teardown_1">teardown</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the end of fit (train + validate), validate, test, predict, or tune.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td>None</td>
</tr>
</tbody>
</table>
<h4 id="test_dataloader_1">test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Testing data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="train_dataloader_1">train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Train data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="transfer_batch_to_device_1">transfer_batch_to_device</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override this hook if your :class:<code>~torch.utils.data.DataLoader</code> returns tensors wrapped in a custom</p>
<p>data structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul>
<li>:class:<code>torch.Tensor</code> or anything that implements <code>.to(...)</code></li>
<li>:class:<code>list</code></li>
<li>:class:<code>dict</code></li>
<li>:class:<code>tuple</code></li>
<li>:class:<code>torchtext.data.batch.Batch</code></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, ...).</p>
<p>Note:
    This hook should only transfer the data and not modify it, nor should it move the data to
    any other device than the one passed in as argument (unless you know what you are doing).
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be transferred to a new device.</td>
<td>None</td>
</tr>
<tr>
<td>device</td>
<td>None</td>
<td>The target device as defined in PyTorch.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A reference to the data on the new device.</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def transfer_batch_to_device(self, batch, device, dataloader_idx):
    if isinstance(batch, CustomBatch):
        # move all tensors in your custom data structure to the device
        batch.samples = batch.samples.to(device)
        batch.targets = batch.targets.to(device)
    elif dataloader_idx == 0:
        # skip device transfer for the first dataloader or anything you wish
        pass
    else:
        batch = super().transfer_batch_to_device(data, device)
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>move_data_to_device</code> |
| -  | meth:<code>apply_to_collection</code> |</p>
<h4 id="val_dataloader_1">val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Validation data loader for the given input</td>
</tr>
</tbody>
</table>
<h3 id="indiandiabeticretinopythydetectionlocalization">IndianDiabeticRetinopythyDetectionLocalization</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">IndianDiabeticRetinopythyDetectionLocalization</span><span class="p">(</span>
    <span class="n">train_transform</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">image_dir_train</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">image_dir_test</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file_train_disk</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file_test_disk</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file_train_fovea</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file_test_fovea</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">test_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_test_split</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="ancestors-in-mro_2">Ancestors (in MRO)</h4>
<ul>
<li>pytorch_lightning.core.datamodule.LightningDataModule</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
</ul>
<h4 id="class-variables_2">Class variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">name</span>
</code></pre></div>
<h4 id="static-methods_2">Static methods</h4>
<h4 id="add_argparse_args_2">add_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">add_argparse_args</span><span class="p">(</span>
    <span class="n">parent_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span>
</code></pre></div>
<p>Extends existing argparse by default <code>LightningDataModule</code> attributes.</p>
<h4 id="from_argparse_args_2">from_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_argparse_args</span><span class="p">(</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from CLI arguments.</p>
<p>Args:
    args: The parser or namespace to take arguments from. Only known arguments will be
        parsed and passed to the :class:<code>~pytorch_lightning.core.datamodule.LightningDataModule</code>.
    **kwargs: Additional keyword arguments that may override ones in the parser or namespace.
        These must be valid DataModule arguments.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>parser = ArgumentParser(add_help=False)
parser = LightningDataModule.add_argparse_args(parser)
module = LightningDataModule.from_argparse_args(args)
</code></pre></div>
<h4 id="from_datasets_2">from_datasets</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_datasets</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from torch.utils.data.Dataset.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>train_dataset</td>
<td>None</td>
<td>(optional) Dataset to be used for train_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>val_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for val_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>test_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for test_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Batch size to use for each dataloader. Default is 1.</td>
<td>None</td>
</tr>
<tr>
<td>num_workers</td>
<td>None</td>
<td>Number of subprocesses to use for data loading. 0 means that the</td>
<td></td>
</tr>
<tr>
<td>data will be loaded in the main process. Number of CPUs available.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="get_init_arguments_and_types_2">get_init_arguments_and_types</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_init_arguments_and_types</span><span class="p">(</span>

<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</code></pre></div>
<p>Scans the DataModule signature and returns argument names, types and default values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List with tuples of 3 values:</td>
</tr>
<tr>
<td>(argument name, set with argument types, argument default value).</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="instance-variables_2">Instance variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">dims</span>
</code></pre></div>
<p>A tuple describing the shape of your data. Extra functionality exposed in <code>size</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_prepared_data</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.prepare_data()</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. It is mutable by the user.</p>
<p>For the frozen set of initial hyperparameters, use :attr:<code>hparams_initial</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams_initial</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. These contents are read-only.</p>
<p>Manual updates to the saved hyperparameters can instead be performed through :attr:<code>hparams</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">test_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to test dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">train_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to train dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">val_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to validation dataset.</p>
<h4 id="methods_2">Methods</h4>
<h4 id="on_after_batch_transfer_2">on_after_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_after_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = gpu_transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_before_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_before_batch_transfer_2">on_before_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_before_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_after_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_load_checkpoint_2">on_load_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning to restore your model.
If you saved something with :meth:<code>on_save_checkpoint</code> this is your chance to restore this.</p>
<p>Args:
    checkpoint: Loaded checkpoint</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_load_checkpoint(self, checkpoint):
    # 99% of the time you don&#39;t need to implement this method
    self.something_cool_i_want_to_save = checkpoint[&#39;something_cool_i_want_to_save&#39;]
</code></pre></div>
<p>Note:
    Lightning auto-restores global step, epoch, and train state including amp scaling.
    There is no need for you to restore anything regarding training.</p>
<h4 id="on_predict_dataloader_2">on_predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the predict dataloader.</p>
<h4 id="on_save_checkpoint_2">on_save_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning when saving a checkpoint to give you a chance to store anything
else you might want to save.</p>
<p>Args:
    checkpoint: The full checkpoint dictionary before it gets dumped to a file.
        Implementations of this hook can insert additional data into this dictionary.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_save_checkpoint(self, checkpoint):
    # 99% of use cases you don&#39;t need to implement this method
    checkpoint[&#39;something_cool_i_want_to_save&#39;] = my_cool_pickable_object
</code></pre></div>
<p>Note:
    Lightning saves all aspects of training (epoch, global step, etc...)
    including amp scaling.
    There is no need for you to store anything about training.</p>
<h4 id="on_test_dataloader_2">on_test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the test dataloader.</p>
<h4 id="on_train_dataloader_2">on_train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the train dataloader.</p>
<h4 id="on_val_dataloader_2">on_val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the val dataloader.</p>
<h4 id="predict_dataloader_2">predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]]</span>
</code></pre></div>
<p>Implement one or multiple PyTorch DataLoaders for prediction.</p>
<p>It's recommended that all data downloads and preparation happen in :meth:<code>prepare_data</code>.</p>
<ul>
<li>:meth:<code>~pytorch_lightning.trainer.Trainer.fit</code></li>
<li>...</li>
<li>:meth:<code>prepare_data</code></li>
<li>:meth:<code>train_dataloader</code></li>
<li>:meth:<code>val_dataloader</code></li>
<li>:meth:<code>test_dataloader</code></li>
</ul>
<p>Note:
    Lightning adds the correct sampler for distributed and arbitrary hardware
    There is no need to set it yourself.</p>
<p>Return:
    A :class:<code>torch.utils.data.DataLoader</code> or a sequence of them specifying prediction samples.</p>
<p>Note:
    In the case where you return multiple prediction dataloaders, the :meth:<code>predict</code>
    will have an argument <code>dataloader_idx</code> which matches the order here.</p>
<h4 id="prepare_data_2">prepare_data</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Use this to download and prepare data.</p>
<p>.. warning:: DO NOT set state to the model (use <code>setup</code> instead)
    since this is NOT called on every GPU in DDP/TPU</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def prepare_data(self):
    # good
    download_data()
    tokenize()
    etc()

    # bad
    self.split = data_split
    self.some_state = some_other_state()
</code></pre></div>
<p>In DDP prepare_data can be called in two ways (using Trainer(prepare_data_per_node)):</p>
<ol>
<li>Once per node. This is the default and is only called on LOCAL_RANK=0.</li>
<li>Once in total. Only called on GLOBAL_RANK=0.</li>
</ol>
<p>Example::</p>
<div class="highlight"><pre><span></span><code># DEFAULT
# called once per node on LOCAL_RANK=0 of that node
Trainer(prepare_data_per_node=True)

# call on GLOBAL_RANK=0 (great for shared file systems)
Trainer(prepare_data_per_node=False)
</code></pre></div>
<p>Note:
    Setting <code>prepare_data_per_node</code> with the trainer flag is deprecated and will be removed in v1.7.0.
    Please set <code>prepare_data_per_node</code> in LightningDataModule or LightningModule directly instead.</p>
<p>This is called before requesting the dataloaders:</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code>model.prepare_data()
initialize_distributed()
model.setup(stage)
model.train_dataloader()
model.val_dataloader()
model.test_dataloader()
</code></pre></div>
<h4 id="save_hyperparameters_2">save_hyperparameters</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">save_hyperparameters</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="n">ignore</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">frame</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">frame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logger</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Save arguments to <code>hparams</code> attribute.</p>
<p>Args:
    args: single object of <code>dict</code>, <code>NameSpace</code> or <code>OmegaConf</code>
        or string names or arguments from class <code>__init__</code>
    ignore: an argument name or a list of argument names from
        class <code>__init__</code> to be ignored
    frame: a frame object. Default is None
    logger: Whether to send the hyperparameters to the logger. Default: True</p>
<p>Example::
    &gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
    ...     def <strong>init</strong>(self, arg1, arg2, arg3):
    ...         super().<strong>init</strong>()
    ...         # manually assign arguments
    ...         self.save_hyperparameters('arg1', 'arg3')
    ...     def forward(self, <em>args, </em>*kwargs):
    ...         ...
    &gt;&gt;&gt; model = ManuallyArgsModel(1, 'abc', 3.14)
    &gt;&gt;&gt; model.hparams
    "arg1": 1
    "arg3": 3.14</p>
<div class="highlight"><pre><span></span><code>&gt;&gt;&gt; class AutomaticArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # equivalent automatic
...         self.save_hyperparameters()
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = AutomaticArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg2&quot;: abc
&quot;arg3&quot;: 3.14

&gt;&gt;&gt; class SingleArgModel(HyperparametersMixin):
...     def __init__(self, params):
...         super().__init__()
...         # manually assign single argument
...         self.save_hyperparameters(params)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = SingleArgModel(Namespace(p1=1, p2=&#39;abc&#39;, p3=3.14))
&gt;&gt;&gt; model.hparams
&quot;p1&quot;: 1
&quot;p2&quot;: abc
&quot;p3&quot;: 3.14

&gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # pass argument(s) to ignore as a string or in a list
...         self.save_hyperparameters(ignore=&#39;arg2&#39;)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = ManuallyArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg3&quot;: 3.14
</code></pre></div>
<h4 id="setup_2">setup</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">setup</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the beginning of fit (train + validate), validate, test, and predict. This is a good hook when</p>
<p>you need to build models dynamically or adjust something about them. This hook is called on every process
when using DDP.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td></td>
</tr>
<tr>
<td>Example::</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>class LitModel</td>
<td>...</td>
<td>def <strong>init</strong>(self):</td>
<td></td>
</tr>
<tr>
<td>self.l1 = None</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>def prepare_data(self):
    download_data()
    tokenize()</p>
<div class="highlight"><pre><span></span><code># don&#39;t do this
self.something = else
</code></pre></div>
<p>def setup(stage):
    data = Load_data(...)
    self.l1 = nn.Linear(28, data.num_classes) | None |</p>
<h4 id="size_2">size</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">size</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]]</span>
</code></pre></div>
<p>Return the dimension of each input either as a tuple or list of tuples. You can index this just as you</p>
<p>would with a torch tensor.</p>
<h4 id="teardown_2">teardown</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the end of fit (train + validate), validate, test, predict, or tune.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td>None</td>
</tr>
</tbody>
</table>
<h4 id="test_dataloader_2">test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Testing data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="train_dataloader_2">train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Train data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="transfer_batch_to_device_2">transfer_batch_to_device</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override this hook if your :class:<code>~torch.utils.data.DataLoader</code> returns tensors wrapped in a custom</p>
<p>data structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul>
<li>:class:<code>torch.Tensor</code> or anything that implements <code>.to(...)</code></li>
<li>:class:<code>list</code></li>
<li>:class:<code>dict</code></li>
<li>:class:<code>tuple</code></li>
<li>:class:<code>torchtext.data.batch.Batch</code></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, ...).</p>
<p>Note:
    This hook should only transfer the data and not modify it, nor should it move the data to
    any other device than the one passed in as argument (unless you know what you are doing).
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be transferred to a new device.</td>
<td>None</td>
</tr>
<tr>
<td>device</td>
<td>None</td>
<td>The target device as defined in PyTorch.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A reference to the data on the new device.</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def transfer_batch_to_device(self, batch, device, dataloader_idx):
    if isinstance(batch, CustomBatch):
        # move all tensors in your custom data structure to the device
        batch.samples = batch.samples.to(device)
        batch.targets = batch.targets.to(device)
    elif dataloader_idx == 0:
        # skip device transfer for the first dataloader or anything you wish
        pass
    else:
        batch = super().transfer_batch_to_device(data, device)
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>move_data_to_device</code> |
| -  | meth:<code>apply_to_collection</code> |</p>
<h4 id="val_dataloader_2">val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Validation data loader for the given input</td>
</tr>
</tbody>
</table>
<h3 id="retinamnist">RetinaMNIST</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">RetinaMNIST</span><span class="p">(</span>
    <span class="n">data_dir</span><span class="p">,</span>
    <span class="n">train_transform</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="n">balanced_sampling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="ancestors-in-mro_3">Ancestors (in MRO)</h4>
<ul>
<li>pytorch_lightning.core.datamodule.LightningDataModule</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
</ul>
<h4 id="class-variables_3">Class variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">name</span>
</code></pre></div>
<h4 id="static-methods_3">Static methods</h4>
<h4 id="add_argparse_args_3">add_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">add_argparse_args</span><span class="p">(</span>
    <span class="n">parent_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span>
</code></pre></div>
<p>Extends existing argparse by default <code>LightningDataModule</code> attributes.</p>
<h4 id="from_argparse_args_3">from_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_argparse_args</span><span class="p">(</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from CLI arguments.</p>
<p>Args:
    args: The parser or namespace to take arguments from. Only known arguments will be
        parsed and passed to the :class:<code>~pytorch_lightning.core.datamodule.LightningDataModule</code>.
    **kwargs: Additional keyword arguments that may override ones in the parser or namespace.
        These must be valid DataModule arguments.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>parser = ArgumentParser(add_help=False)
parser = LightningDataModule.add_argparse_args(parser)
module = LightningDataModule.from_argparse_args(args)
</code></pre></div>
<h4 id="from_datasets_3">from_datasets</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_datasets</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from torch.utils.data.Dataset.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>train_dataset</td>
<td>None</td>
<td>(optional) Dataset to be used for train_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>val_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for val_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>test_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for test_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Batch size to use for each dataloader. Default is 1.</td>
<td>None</td>
</tr>
<tr>
<td>num_workers</td>
<td>None</td>
<td>Number of subprocesses to use for data loading. 0 means that the</td>
<td></td>
</tr>
<tr>
<td>data will be loaded in the main process. Number of CPUs available.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="get_init_arguments_and_types_3">get_init_arguments_and_types</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_init_arguments_and_types</span><span class="p">(</span>

<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</code></pre></div>
<p>Scans the DataModule signature and returns argument names, types and default values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List with tuples of 3 values:</td>
</tr>
<tr>
<td>(argument name, set with argument types, argument default value).</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="instance-variables_3">Instance variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">dims</span>
</code></pre></div>
<p>A tuple describing the shape of your data. Extra functionality exposed in <code>size</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_prepared_data</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.prepare_data()</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. It is mutable by the user.</p>
<p>For the frozen set of initial hyperparameters, use :attr:<code>hparams_initial</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams_initial</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. These contents are read-only.</p>
<p>Manual updates to the saved hyperparameters can instead be performed through :attr:<code>hparams</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">test_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to test dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">train_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to train dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">val_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to validation dataset.</p>
<h4 id="methods_3">Methods</h4>
<h4 id="on_after_batch_transfer_3">on_after_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_after_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = gpu_transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_before_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_before_batch_transfer_3">on_before_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_before_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_after_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_load_checkpoint_3">on_load_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning to restore your model.
If you saved something with :meth:<code>on_save_checkpoint</code> this is your chance to restore this.</p>
<p>Args:
    checkpoint: Loaded checkpoint</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_load_checkpoint(self, checkpoint):
    # 99% of the time you don&#39;t need to implement this method
    self.something_cool_i_want_to_save = checkpoint[&#39;something_cool_i_want_to_save&#39;]
</code></pre></div>
<p>Note:
    Lightning auto-restores global step, epoch, and train state including amp scaling.
    There is no need for you to restore anything regarding training.</p>
<h4 id="on_predict_dataloader_3">on_predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the predict dataloader.</p>
<h4 id="on_save_checkpoint_3">on_save_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning when saving a checkpoint to give you a chance to store anything
else you might want to save.</p>
<p>Args:
    checkpoint: The full checkpoint dictionary before it gets dumped to a file.
        Implementations of this hook can insert additional data into this dictionary.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_save_checkpoint(self, checkpoint):
    # 99% of use cases you don&#39;t need to implement this method
    checkpoint[&#39;something_cool_i_want_to_save&#39;] = my_cool_pickable_object
</code></pre></div>
<p>Note:
    Lightning saves all aspects of training (epoch, global step, etc...)
    including amp scaling.
    There is no need for you to store anything about training.</p>
<h4 id="on_test_dataloader_3">on_test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the test dataloader.</p>
<h4 id="on_train_dataloader_3">on_train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the train dataloader.</p>
<h4 id="on_val_dataloader_3">on_val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the val dataloader.</p>
<h4 id="predict_dataloader_3">predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]]</span>
</code></pre></div>
<p>Implement one or multiple PyTorch DataLoaders for prediction.</p>
<p>It's recommended that all data downloads and preparation happen in :meth:<code>prepare_data</code>.</p>
<ul>
<li>:meth:<code>~pytorch_lightning.trainer.Trainer.fit</code></li>
<li>...</li>
<li>:meth:<code>prepare_data</code></li>
<li>:meth:<code>train_dataloader</code></li>
<li>:meth:<code>val_dataloader</code></li>
<li>:meth:<code>test_dataloader</code></li>
</ul>
<p>Note:
    Lightning adds the correct sampler for distributed and arbitrary hardware
    There is no need to set it yourself.</p>
<p>Return:
    A :class:<code>torch.utils.data.DataLoader</code> or a sequence of them specifying prediction samples.</p>
<p>Note:
    In the case where you return multiple prediction dataloaders, the :meth:<code>predict</code>
    will have an argument <code>dataloader_idx</code> which matches the order here.</p>
<h4 id="prepare_data_3">prepare_data</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Use this to download and prepare data.</p>
<p>.. warning:: DO NOT set state to the model (use <code>setup</code> instead)
    since this is NOT called on every GPU in DDP/TPU</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def prepare_data(self):
    # good
    download_data()
    tokenize()
    etc()

    # bad
    self.split = data_split
    self.some_state = some_other_state()
</code></pre></div>
<p>In DDP prepare_data can be called in two ways (using Trainer(prepare_data_per_node)):</p>
<ol>
<li>Once per node. This is the default and is only called on LOCAL_RANK=0.</li>
<li>Once in total. Only called on GLOBAL_RANK=0.</li>
</ol>
<p>Example::</p>
<div class="highlight"><pre><span></span><code># DEFAULT
# called once per node on LOCAL_RANK=0 of that node
Trainer(prepare_data_per_node=True)

# call on GLOBAL_RANK=0 (great for shared file systems)
Trainer(prepare_data_per_node=False)
</code></pre></div>
<p>Note:
    Setting <code>prepare_data_per_node</code> with the trainer flag is deprecated and will be removed in v1.7.0.
    Please set <code>prepare_data_per_node</code> in LightningDataModule or LightningModule directly instead.</p>
<p>This is called before requesting the dataloaders:</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code>model.prepare_data()
initialize_distributed()
model.setup(stage)
model.train_dataloader()
model.val_dataloader()
model.test_dataloader()
</code></pre></div>
<h4 id="save_hyperparameters_3">save_hyperparameters</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">save_hyperparameters</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="n">ignore</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">frame</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">frame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logger</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Save arguments to <code>hparams</code> attribute.</p>
<p>Args:
    args: single object of <code>dict</code>, <code>NameSpace</code> or <code>OmegaConf</code>
        or string names or arguments from class <code>__init__</code>
    ignore: an argument name or a list of argument names from
        class <code>__init__</code> to be ignored
    frame: a frame object. Default is None
    logger: Whether to send the hyperparameters to the logger. Default: True</p>
<p>Example::
    &gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
    ...     def <strong>init</strong>(self, arg1, arg2, arg3):
    ...         super().<strong>init</strong>()
    ...         # manually assign arguments
    ...         self.save_hyperparameters('arg1', 'arg3')
    ...     def forward(self, <em>args, </em>*kwargs):
    ...         ...
    &gt;&gt;&gt; model = ManuallyArgsModel(1, 'abc', 3.14)
    &gt;&gt;&gt; model.hparams
    "arg1": 1
    "arg3": 3.14</p>
<div class="highlight"><pre><span></span><code>&gt;&gt;&gt; class AutomaticArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # equivalent automatic
...         self.save_hyperparameters()
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = AutomaticArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg2&quot;: abc
&quot;arg3&quot;: 3.14

&gt;&gt;&gt; class SingleArgModel(HyperparametersMixin):
...     def __init__(self, params):
...         super().__init__()
...         # manually assign single argument
...         self.save_hyperparameters(params)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = SingleArgModel(Namespace(p1=1, p2=&#39;abc&#39;, p3=3.14))
&gt;&gt;&gt; model.hparams
&quot;p1&quot;: 1
&quot;p2&quot;: abc
&quot;p3&quot;: 3.14

&gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # pass argument(s) to ignore as a string or in a list
...         self.save_hyperparameters(ignore=&#39;arg2&#39;)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = ManuallyArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg3&quot;: 3.14
</code></pre></div>
<h4 id="setup_3">setup</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">setup</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the beginning of fit (train + validate), validate, test, and predict. This is a good hook when</p>
<p>you need to build models dynamically or adjust something about them. This hook is called on every process
when using DDP.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td></td>
</tr>
<tr>
<td>Example::</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>class LitModel</td>
<td>...</td>
<td>def <strong>init</strong>(self):</td>
<td></td>
</tr>
<tr>
<td>self.l1 = None</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>def prepare_data(self):
    download_data()
    tokenize()</p>
<div class="highlight"><pre><span></span><code># don&#39;t do this
self.something = else
</code></pre></div>
<p>def setup(stage):
    data = Load_data(...)
    self.l1 = nn.Linear(28, data.num_classes) | None |</p>
<h4 id="size_3">size</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">size</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]]</span>
</code></pre></div>
<p>Return the dimension of each input either as a tuple or list of tuples. You can index this just as you</p>
<p>would with a torch tensor.</p>
<h4 id="teardown_3">teardown</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the end of fit (train + validate), validate, test, predict, or tune.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td>None</td>
</tr>
</tbody>
</table>
<h4 id="test_dataloader_3">test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Testing data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="train_dataloader_3">train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Train data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="transfer_batch_to_device_3">transfer_batch_to_device</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override this hook if your :class:<code>~torch.utils.data.DataLoader</code> returns tensors wrapped in a custom</p>
<p>data structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul>
<li>:class:<code>torch.Tensor</code> or anything that implements <code>.to(...)</code></li>
<li>:class:<code>list</code></li>
<li>:class:<code>dict</code></li>
<li>:class:<code>tuple</code></li>
<li>:class:<code>torchtext.data.batch.Batch</code></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, ...).</p>
<p>Note:
    This hook should only transfer the data and not modify it, nor should it move the data to
    any other device than the one passed in as argument (unless you know what you are doing).
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be transferred to a new device.</td>
<td>None</td>
</tr>
<tr>
<td>device</td>
<td>None</td>
<td>The target device as defined in PyTorch.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A reference to the data on the new device.</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def transfer_batch_to_device(self, batch, device, dataloader_idx):
    if isinstance(batch, CustomBatch):
        # move all tensors in your custom data structure to the device
        batch.samples = batch.samples.to(device)
        batch.targets = batch.targets.to(device)
    elif dataloader_idx == 0:
        # skip device transfer for the first dataloader or anything you wish
        pass
    else:
        batch = super().transfer_batch_to_device(data, device)
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>move_data_to_device</code> |
| -  | meth:<code>apply_to_collection</code> |</p>
<h4 id="val_dataloader_3">val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Validation data loader for the given input</td>
</tr>
</tbody>
</table>
<h3 id="ssldiabeticretinopythydetection">SSLDiabeticRetinopythyDetection</h3>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">SSLDiabeticRetinopythyDetection</span><span class="p">(</span>
    <span class="n">ssl_transform</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">image_dir</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">csv_file</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="n">test_transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_test_split</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.98</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
    <span class="n">balanced_sampling</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">use_test_fraction</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="ancestors-in-mro_4">Ancestors (in MRO)</h4>
<ul>
<li>pytorch_lightning.core.datamodule.LightningDataModule</li>
<li>pytorch_lightning.core.hooks.CheckpointHooks</li>
<li>pytorch_lightning.core.hooks.DataHooks</li>
<li>pytorch_lightning.core.mixins.hparams_mixin.HyperparametersMixin</li>
</ul>
<h4 id="class-variables_4">Class variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">name</span>
</code></pre></div>
<h4 id="static-methods_4">Static methods</h4>
<h4 id="add_argparse_args_4">add_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">add_argparse_args</span><span class="p">(</span>
    <span class="n">parent_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span>
</code></pre></div>
<p>Extends existing argparse by default <code>LightningDataModule</code> attributes.</p>
<h4 id="from_argparse_args_4">from_argparse_args</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_argparse_args</span><span class="p">(</span>
    <span class="n">args</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">argparse</span><span class="o">.</span><span class="n">Namespace</span><span class="p">,</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from CLI arguments.</p>
<p>Args:
    args: The parser or namespace to take arguments from. Only known arguments will be
        parsed and passed to the :class:<code>~pytorch_lightning.core.datamodule.LightningDataModule</code>.
    **kwargs: Additional keyword arguments that may override ones in the parser or namespace.
        These must be valid DataModule arguments.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>parser = ArgumentParser(add_help=False)
parser = LightningDataModule.add_argparse_args(parser)
module = LightningDataModule.from_argparse_args(args)
</code></pre></div>
<h4 id="from_datasets_4">from_datasets</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">from_datasets</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">Mapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>
<p>Create an instance from torch.utils.data.Dataset.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>train_dataset</td>
<td>None</td>
<td>(optional) Dataset to be used for train_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>val_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for val_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>test_dataset</td>
<td>None</td>
<td>(optional) Dataset or list of Dataset to be used for test_dataloader()</td>
<td>None</td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Batch size to use for each dataloader. Default is 1.</td>
<td>None</td>
</tr>
<tr>
<td>num_workers</td>
<td>None</td>
<td>Number of subprocesses to use for data loading. 0 means that the</td>
<td></td>
</tr>
<tr>
<td>data will be loaded in the main process. Number of CPUs available.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="get_init_arguments_and_types_4">get_init_arguments_and_types</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_init_arguments_and_types</span><span class="p">(</span>

<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span>
</code></pre></div>
<p>Scans the DataModule signature and returns argument names, types and default values.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List with tuples of 3 values:</td>
</tr>
<tr>
<td>(argument name, set with argument types, argument default value).</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="instance-variables_4">Instance variables</h4>
<div class="highlight"><pre><span></span><code><span class="n">dims</span>
</code></pre></div>
<p>A tuple describing the shape of your data. Extra functionality exposed in <code>size</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_prepared_data</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.prepare_data()</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_setup_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.setup(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_fit</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='fit')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_predict</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='predict')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_test</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='test')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">has_teardown_validate</span>
</code></pre></div>
<p>Return bool letting you know if <code>datamodule.teardown(stage='validate')</code> has been called or not.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. It is mutable by the user.</p>
<p>For the frozen set of initial hyperparameters, use :attr:<code>hparams_initial</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">hparams_initial</span>
</code></pre></div>
<p>The collection of hyperparameters saved with :meth:<code>save_hyperparameters</code>. These contents are read-only.</p>
<p>Manual updates to the saved hyperparameters can instead be performed through :attr:<code>hparams</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">test_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to test dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">train_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to train dataset.</p>
<div class="highlight"><pre><span></span><code><span class="n">val_transforms</span>
</code></pre></div>
<p>Optional transforms (or collection of transforms) you can apply to validation dataset.</p>
<h4 id="methods_4">Methods</h4>
<h4 id="on_after_batch_transfer_4">on_after_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_after_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_after_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = gpu_transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_before_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_before_batch_transfer_4">on_before_batch_transfer</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_before_batch_transfer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<p>Note:
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be altered or augmented.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A batch of data</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_before_batch_transfer(self, batch, dataloader_idx):
    batch[&#39;x&#39;] = transforms(batch[&#39;x&#39;])
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>on_after_batch_transfer</code> |
| -  | meth:<code>transfer_batch_to_device</code> |</p>
<h4 id="on_load_checkpoint_4">on_load_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_load_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning to restore your model.
If you saved something with :meth:<code>on_save_checkpoint</code> this is your chance to restore this.</p>
<p>Args:
    checkpoint: Loaded checkpoint</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_load_checkpoint(self, checkpoint):
    # 99% of the time you don&#39;t need to implement this method
    self.something_cool_i_want_to_save = checkpoint[&#39;something_cool_i_want_to_save&#39;]
</code></pre></div>
<p>Note:
    Lightning auto-restores global step, epoch, and train state including amp scaling.
    There is no need for you to restore anything regarding training.</p>
<h4 id="on_predict_dataloader_4">on_predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the predict dataloader.</p>
<h4 id="on_save_checkpoint_4">on_save_checkpoint</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_save_checkpoint</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">checkpoint</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called by Lightning when saving a checkpoint to give you a chance to store anything
else you might want to save.</p>
<p>Args:
    checkpoint: The full checkpoint dictionary before it gets dumped to a file.
        Implementations of this hook can insert additional data into this dictionary.</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def on_save_checkpoint(self, checkpoint):
    # 99% of use cases you don&#39;t need to implement this method
    checkpoint[&#39;something_cool_i_want_to_save&#39;] = my_cool_pickable_object
</code></pre></div>
<p>Note:
    Lightning saves all aspects of training (epoch, global step, etc...)
    including amp scaling.
    There is no need for you to store anything about training.</p>
<h4 id="on_test_dataloader_4">on_test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the test dataloader.</p>
<h4 id="on_train_dataloader_4">on_train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the train dataloader.</p>
<h4 id="on_val_dataloader_4">on_val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">on_val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called before requesting the val dataloader.</p>
<h4 id="predict_dataloader_4">predict_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]]</span>
</code></pre></div>
<p>Implement one or multiple PyTorch DataLoaders for prediction.</p>
<p>It's recommended that all data downloads and preparation happen in :meth:<code>prepare_data</code>.</p>
<ul>
<li>:meth:<code>~pytorch_lightning.trainer.Trainer.fit</code></li>
<li>...</li>
<li>:meth:<code>prepare_data</code></li>
<li>:meth:<code>train_dataloader</code></li>
<li>:meth:<code>val_dataloader</code></li>
<li>:meth:<code>test_dataloader</code></li>
</ul>
<p>Note:
    Lightning adds the correct sampler for distributed and arbitrary hardware
    There is no need to set it yourself.</p>
<p>Return:
    A :class:<code>torch.utils.data.DataLoader</code> or a sequence of them specifying prediction samples.</p>
<p>Note:
    In the case where you return multiple prediction dataloaders, the :meth:<code>predict</code>
    will have an argument <code>dataloader_idx</code> which matches the order here.</p>
<h4 id="prepare_data_4">prepare_data</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Use this to download and prepare data.</p>
<p>.. warning:: DO NOT set state to the model (use <code>setup</code> instead)
    since this is NOT called on every GPU in DDP/TPU</p>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def prepare_data(self):
    # good
    download_data()
    tokenize()
    etc()

    # bad
    self.split = data_split
    self.some_state = some_other_state()
</code></pre></div>
<p>In DDP prepare_data can be called in two ways (using Trainer(prepare_data_per_node)):</p>
<ol>
<li>Once per node. This is the default and is only called on LOCAL_RANK=0.</li>
<li>Once in total. Only called on GLOBAL_RANK=0.</li>
</ol>
<p>Example::</p>
<div class="highlight"><pre><span></span><code># DEFAULT
# called once per node on LOCAL_RANK=0 of that node
Trainer(prepare_data_per_node=True)

# call on GLOBAL_RANK=0 (great for shared file systems)
Trainer(prepare_data_per_node=False)
</code></pre></div>
<p>Note:
    Setting <code>prepare_data_per_node</code> with the trainer flag is deprecated and will be removed in v1.7.0.
    Please set <code>prepare_data_per_node</code> in LightningDataModule or LightningModule directly instead.</p>
<p>This is called before requesting the dataloaders:</p>
<p>.. code-block:: python</p>
<div class="highlight"><pre><span></span><code>model.prepare_data()
initialize_distributed()
model.setup(stage)
model.train_dataloader()
model.val_dataloader()
model.test_dataloader()
</code></pre></div>
<h4 id="save_hyperparameters_4">save_hyperparameters</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">save_hyperparameters</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="n">ignore</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">,</span> <span class="n">NoneType</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">frame</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">frame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">logger</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Save arguments to <code>hparams</code> attribute.</p>
<p>Args:
    args: single object of <code>dict</code>, <code>NameSpace</code> or <code>OmegaConf</code>
        or string names or arguments from class <code>__init__</code>
    ignore: an argument name or a list of argument names from
        class <code>__init__</code> to be ignored
    frame: a frame object. Default is None
    logger: Whether to send the hyperparameters to the logger. Default: True</p>
<p>Example::
    &gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
    ...     def <strong>init</strong>(self, arg1, arg2, arg3):
    ...         super().<strong>init</strong>()
    ...         # manually assign arguments
    ...         self.save_hyperparameters('arg1', 'arg3')
    ...     def forward(self, <em>args, </em>*kwargs):
    ...         ...
    &gt;&gt;&gt; model = ManuallyArgsModel(1, 'abc', 3.14)
    &gt;&gt;&gt; model.hparams
    "arg1": 1
    "arg3": 3.14</p>
<div class="highlight"><pre><span></span><code>&gt;&gt;&gt; class AutomaticArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # equivalent automatic
...         self.save_hyperparameters()
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = AutomaticArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg2&quot;: abc
&quot;arg3&quot;: 3.14

&gt;&gt;&gt; class SingleArgModel(HyperparametersMixin):
...     def __init__(self, params):
...         super().__init__()
...         # manually assign single argument
...         self.save_hyperparameters(params)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = SingleArgModel(Namespace(p1=1, p2=&#39;abc&#39;, p3=3.14))
&gt;&gt;&gt; model.hparams
&quot;p1&quot;: 1
&quot;p2&quot;: abc
&quot;p3&quot;: 3.14

&gt;&gt;&gt; class ManuallyArgsModel(HyperparametersMixin):
...     def __init__(self, arg1, arg2, arg3):
...         super().__init__()
...         # pass argument(s) to ignore as a string or in a list
...         self.save_hyperparameters(ignore=&#39;arg2&#39;)
...     def forward(self, *args, **kwargs):
...         ...
&gt;&gt;&gt; model = ManuallyArgsModel(1, &#39;abc&#39;, 3.14)
&gt;&gt;&gt; model.hparams
&quot;arg1&quot;: 1
&quot;arg3&quot;: 3.14
</code></pre></div>
<h4 id="setup_4">setup</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">setup</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the beginning of fit (train + validate), validate, test, and predict. This is a good hook when</p>
<p>you need to build models dynamically or adjust something about them. This hook is called on every process
when using DDP.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td></td>
</tr>
<tr>
<td>Example::</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>class LitModel</td>
<td>...</td>
<td>def <strong>init</strong>(self):</td>
<td></td>
</tr>
<tr>
<td>self.l1 = None</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>def prepare_data(self):
    download_data()
    tokenize()</p>
<div class="highlight"><pre><span></span><code># don&#39;t do this
self.something = else
</code></pre></div>
<p>def setup(stage):
    data = Load_data(...)
    self.l1 = nn.Linear(28, data.num_classes) | None |</p>
<h4 id="size_4">size</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">size</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dim</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">]]</span>
</code></pre></div>
<p>Return the dimension of each input either as a tuple or list of tuples. You can index this just as you</p>
<p>would with a torch tensor.</p>
<h4 id="teardown_4">teardown</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">stage</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>
<p>Called at the end of fit (train + validate), validate, test, predict, or tune.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>stage</td>
<td>None</td>
<td>either <code>'fit'</code>, <code>'validate'</code>, <code>'test'</code>, or <code>'predict'</code></td>
<td>None</td>
</tr>
</tbody>
</table>
<h4 id="test_dataloader_4">test_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Validation data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="train_dataloader_4">train_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Train data loader for the given input</td>
</tr>
</tbody>
</table>
<h4 id="transfer_batch_to_device_4">transfer_batch_to_device</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">batch</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="n">dataloader_idx</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span>
</code></pre></div>
<p>Override this hook if your :class:<code>~torch.utils.data.DataLoader</code> returns tensors wrapped in a custom</p>
<p>data structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul>
<li>:class:<code>torch.Tensor</code> or anything that implements <code>.to(...)</code></li>
<li>:class:<code>list</code></li>
<li>:class:<code>dict</code></li>
<li>:class:<code>tuple</code></li>
<li>:class:<code>torchtext.data.batch.Batch</code></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, ...).</p>
<p>Note:
    This hook should only transfer the data and not modify it, nor should it move the data to
    any other device than the one passed in as argument (unless you know what you are doing).
    To check the current state of execution of this hook you can use
    <code>self.trainer.training/testing/validating/predicting</code> so that you can
    add different logic as per your requirement.</p>
<p>Note:
    This hook only runs on single GPU training and DDP (no data-parallel).
    Data-Parallel support will come in near future.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>batch</td>
<td>None</td>
<td>A batch of data that needs to be transferred to a new device.</td>
<td>None</td>
</tr>
<tr>
<td>device</td>
<td>None</td>
<td>The target device as defined in PyTorch.</td>
<td>None</td>
</tr>
<tr>
<td>dataloader_idx</td>
<td>None</td>
<td>The index of the dataloader to which the batch belongs.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A reference to the data on the new device.</td>
</tr>
</tbody>
</table>
<p>Example::</p>
<div class="highlight"><pre><span></span><code>def transfer_batch_to_device(self, batch, device, dataloader_idx):
    if isinstance(batch, CustomBatch):
        # move all tensors in your custom data structure to the device
        batch.samples = batch.samples.to(device)
        batch.targets = batch.targets.to(device)
    elif dataloader_idx == 0:
        # skip device transfer for the first dataloader or anything you wish
        pass
    else:
        batch = super().transfer_batch_to_device(data, device)
    return batch |
</code></pre></div>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>MisconfigurationException</td>
<td>If using data-parallel, <code>Trainer(strategy='dp')</code>.</td>
</tr>
</tbody>
</table>
<p>See Also: |
| -  | meth:<code>move_data_to_device</code> |
| -  | meth:<code>apply_to_collection</code> |</p>
<h4 id="val_dataloader_4">val_dataloader</h4>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>output - Validation data loader for the given input</td>
</tr>
</tbody>
</table>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../" title="Index" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Index
              </span>
            </div>
          </a>
        
        
          <a href="../sets/" title="Sets" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Sets
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Powered by
        <a href="http://timothycrosley.github.io/portray">portray.</a>
        You too can
        <a href="http://timothycrosley.github.io/portray">
          portray</a>
        your Python project well using automatic documentation.
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../../../assets/javascripts/workers/search.f8263e09.min.js", "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.4fc53ad4.min.js"></script>
      
    
  </body>
</html>